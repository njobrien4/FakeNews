{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Description of the TSV format:\n",
    "\n",
    "# Column 1: the ID of the statement ([ID].json).\n",
    "# Column 2: the label.\n",
    "# Column 3: the statement.\n",
    "# Column 4: the subject(s).\n",
    "# Column 5: the speaker.\n",
    "# Column 6: the speaker's job title.\n",
    "# Column 7: the state info.\n",
    "# Column 8: the party affiliation.\n",
    "# Column 9-13: the total credit history count, including the current statement.\n",
    "# 9: barely true counts.\n",
    "# 10: false counts.\n",
    "# 11: half true counts.\n",
    "# 12: mostly true counts.\n",
    "# 13: pants on fire counts.\n",
    "# Column 14: the context (venue / location of the speech or statement).\n",
    "import csv\n",
    "import collections\n",
    "import codecs\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "d = collections.OrderedDict()\n",
    "\n",
    "def get_corpus_ratings(filename):\n",
    "    statements =[]\n",
    "    ratings=[]\n",
    "    with open(filename, encoding='utf-8') as f:\n",
    "        tsvin = csv.reader(f, delimiter='\\t')\n",
    "        for line in tsvin:\n",
    "            ratings.append(line[1])\n",
    "            statements.append(line[2])\n",
    "    return statements, np.array(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus, ratings=get_corpus_ratings('liar_dataset/train.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['false', 'half-true', 'mostly-true', ..., 'half-true', 'false',\n",
       "       'pants-fire'], \n",
       "      dtype='<U11')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Says the Annies List political group supports third-trimester abortions on demand.',\n",
       " 'When did the decline of coal start? It started when natural gas took off that started to begin in (President George W.) Bushs administration.',\n",
       " 'Hillary Clinton agrees with John McCain \"by voting to give George Bush the benefit of the doubt on Iran.\"',\n",
       " 'Health care reform legislation is likely to mandate free sex change surgeries.',\n",
       " 'The economic turnaround started at the end of my term.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.247663551402  is dev score for C= 0.001\n",
      "0.252336448598  is dev score for C= 0.01\n",
      "0.249221183801  is dev score for C= 0.1\n",
      "0.244548286604  is dev score for C= 10.0\n",
      "0.228971962617  is dev score for C= 1000.0\n",
      "0.224299065421  is dev score for C= 100000.0\n",
      "0.224299065421  is dev score for C= 10000000.0\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X=vectorizer.fit_transform(corpus)\n",
    "feature_list=vectorizer.get_feature_names()\n",
    "dev_corpus, dev_ratings=get_corpus_ratings(\"liar_dataset/valid.tsv\")\n",
    "vectorizer_2=CountVectorizer(vocabulary = feature_list)\n",
    "X2=vectorizer_2.fit_transform(dev_corpus)\n",
    "for i in [1e-3,1e-2,1e-1,1e1,1e3,1e5,1e7]:\n",
    "    logreg = linear_model.LogisticRegression(C=i)\n",
    "    model = logreg.fit(X,ratings)\n",
    "    predicted=logreg.predict(X2)\n",
    "    score=accuracy_score(dev_ratings,predicted)\n",
    "    print(score, \" is dev score for C=\",i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.235201262826 is test score for C=1e-2\n"
     ]
    }
   ],
   "source": [
    "test_corpus,test_ratings=get_corpus_ratings(\"liar_dataset/test.tsv\")\n",
    "logreg=linear_model.LogisticRegression(C=1e-2)\n",
    "model=logreg.fit(X,ratings)\n",
    "X3=vectorizer_2.fit_transform(test_corpus)\n",
    "predicted=logreg.predict(X3)\n",
    "score=accuracy_score(test_ratings, predicted)\n",
    "print(score, \"is test score for C=1e-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12196"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#removing stop words\n",
    "from stop_words import get_stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.247663551402  is dev score for C= 0.001\n",
      "0.256230529595  is dev score for C= 0.01\n",
      "0.239096573209  is dev score for C= 0.1\n",
      "0.23753894081  is dev score for C= 10.0\n",
      "0.235202492212  is dev score for C= 1000.0\n",
      "0.234423676012  is dev score for C= 100000.0\n",
      "0.232087227414  is dev score for C= 10000000.0\n"
     ]
    }
   ],
   "source": [
    "#same thing but bigrams\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 2))\n",
    "X=vectorizer.fit_transform(corpus)\n",
    "feature_list=vectorizer.get_feature_names()\n",
    "dev_corpus, dev_ratings=get_corpus_ratings(\"liar_dataset/valid.tsv\")\n",
    "vectorizer_2=CountVectorizer(vocabulary = feature_list)\n",
    "X2=vectorizer_2.fit_transform(dev_corpus)\n",
    "for i in [1e-3,1e-2,1e-1,1e1,1e3,1e5,1e7]:\n",
    "    logreg = linear_model.LogisticRegression(C=i)\n",
    "    model = logreg.fit(X,ratings)\n",
    "    predicted=logreg.predict(X2)\n",
    "    score=accuracy_score(dev_ratings,predicted)\n",
    "    print(score, \" is dev score for C=\",i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.201713395639  is dev score for C= 0.001\n",
      "0.248442367601  is dev score for C= 0.01\n",
      "0.232866043614  is dev score for C= 0.1\n",
      "0.235981308411  is dev score for C= 10.0\n",
      "0.249221183801  is dev score for C= 1000.0\n",
      "0.249221183801  is dev score for C= 100000.0\n",
      "0.25  is dev score for C= 10000000.0\n"
     ]
    }
   ],
   "source": [
    "#ngrams and remove stop words\n",
    "vectorizer = CountVectorizer(stop_words=get_stop_words('en'),ngram_range=(1, 2))\n",
    "X=vectorizer.fit_transform(corpus)\n",
    "feature_list=vectorizer.get_feature_names()\n",
    "dev_corpus, dev_ratings=get_corpus_ratings(\"liar_dataset/valid.tsv\")\n",
    "vectorizer_2=CountVectorizer(vocabulary = feature_list)\n",
    "X2=vectorizer_2.fit_transform(dev_corpus)\n",
    "for i in [1e-3,1e-2,1e-1,1e1,1e3,1e5,1e7]:\n",
    "    logreg = linear_model.LogisticRegression(C=i)\n",
    "    model = logreg.fit(X,ratings)\n",
    "    predicted=logreg.predict(X2)\n",
    "    score=accuracy_score(dev_ratings,predicted)\n",
    "    print(score, \" is dev score for C=\",i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.246105919003  is dev score for C= 0.001\n",
      "0.257788161994  is dev score for C= 0.01\n",
      "0.242990654206  is dev score for C= 0.1\n",
      "0.238317757009  is dev score for C= 10.0\n",
      "0.238317757009  is dev score for C= 1000.0\n",
      "0.233644859813  is dev score for C= 100000.0\n",
      "0.235981308411  is dev score for C= 10000000.0\n"
     ]
    }
   ],
   "source": [
    "#same thing but trigrams\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 3))\n",
    "X=vectorizer.fit_transform(corpus)\n",
    "feature_list=vectorizer.get_feature_names()\n",
    "dev_corpus, dev_ratings=get_corpus_ratings(\"liar_dataset/valid.tsv\")\n",
    "vectorizer_2=CountVectorizer(vocabulary = feature_list)\n",
    "X2=vectorizer_2.fit_transform(dev_corpus)\n",
    "for i in [1e-3,1e-2,1e-1,1e1,1e3,1e5,1e7]:\n",
    "    logreg = linear_model.LogisticRegression(C=i)\n",
    "    model = logreg.fit(X,ratings)\n",
    "    predicted=logreg.predict(X2)\n",
    "    score=accuracy_score(dev_ratings,predicted)\n",
    "    print(score, \" is dev score for C=\",i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.246884735202  is dev score for C= 0.001\n",
      "0.258566978193  is dev score for C= 0.01\n",
      "0.244548286604  is dev score for C= 0.1\n",
      "0.246105919003  is dev score for C= 10.0\n",
      "0.248442367601  is dev score for C= 1000.0\n",
      "0.248442367601  is dev score for C= 100000.0\n",
      "0.251557632399  is dev score for C= 10000000.0\n"
     ]
    }
   ],
   "source": [
    "#same thing but 4-grams\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 4))\n",
    "X=vectorizer.fit_transform(corpus)\n",
    "feature_list=vectorizer.get_feature_names()\n",
    "dev_corpus, dev_ratings=get_corpus_ratings(\"liar_dataset/valid.tsv\")\n",
    "vectorizer_2=CountVectorizer(vocabulary = feature_list)\n",
    "X2=vectorizer_2.fit_transform(dev_corpus)\n",
    "for i in [1e-3,1e-2,1e-1,1e1,1e3,1e5,1e7]:\n",
    "    logreg = linear_model.LogisticRegression(C=i)\n",
    "    model = logreg.fit(X,ratings)\n",
    "    predicted=logreg.predict(X2)\n",
    "    score=accuracy_score(dev_ratings,predicted)\n",
    "    print(score, \" is dev score for C=\",i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.202492211838  is dev score for C= 0.001\n",
      "0.244548286604  is dev score for C= 0.01\n",
      "0.239096573209  is dev score for C= 0.1\n",
      "0.235202492212  is dev score for C= 10.0\n"
     ]
    }
   ],
   "source": [
    "#same thing but remove stopwords\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 4),stop_words='english')\n",
    "X=vectorizer.fit_transform(corpus)\n",
    "feature_list=vectorizer.get_feature_names()\n",
    "dev_corpus, dev_ratings=get_corpus_ratings(\"liar_dataset/valid.tsv\")\n",
    "vectorizer_2=CountVectorizer(vocabulary = feature_list)\n",
    "X2=vectorizer_2.fit_transform(dev_corpus)\n",
    "for i in [1e-3,1e-2,1e-1,1e1]:\n",
    "    logreg = linear_model.LogisticRegression(C=i)\n",
    "    model = logreg.fit(X,ratings)\n",
    "    predicted=logreg.predict(X2)\n",
    "    score=accuracy_score(dev_ratings,predicted)\n",
    "    print(score, \" is dev score for C=\",i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.246884735202  is dev score for C= 0.001\n",
      "0.258566978193  is dev score for C= 0.01\n",
      "0.250778816199  is dev score for C= 0.1\n",
      "0.246884735202  is dev score for C= 10.0\n",
      "0.251557632399  is dev score for C= 1000.0\n",
      "0.248442367601  is dev score for C= 100000.0\n",
      "0.250778816199  is dev score for C= 10000000.0\n"
     ]
    }
   ],
   "source": [
    "#same thing but 5-grams\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 5))\n",
    "X=vectorizer.fit_transform(corpus)\n",
    "feature_list=vectorizer.get_feature_names()\n",
    "dev_corpus, dev_ratings=get_corpus_ratings(\"liar_dataset/valid.tsv\")\n",
    "vectorizer_2=CountVectorizer(vocabulary = feature_list)\n",
    "X2=vectorizer_2.fit_transform(dev_corpus)\n",
    "for i in [1e-3,1e-2,1e-1,1e1,1e3,1e5,1e7]:\n",
    "    logreg = linear_model.LogisticRegression(C=i)\n",
    "    model = logreg.fit(X,ratings)\n",
    "    predicted=logreg.predict(X2)\n",
    "    score=accuracy_score(dev_ratings,predicted)\n",
    "    print(score, \" is dev score for C=\",i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12196  is feature list len for ngram:  1\n",
      "95883  is feature list len for ngram:  2\n",
      "228132  is feature list len for ngram:  3\n",
      "369863  is feature list len for ngram:  4\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,5):\n",
    "    vectorizer = CountVectorizer(ngram_range=(1, i))\n",
    "    X=vectorizer.fit_transform(corpus)\n",
    "    feature_list=vectorizer.get_feature_names()\n",
    "    print(len(feature_list), \" is feature list len for ngram: \",i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.246884735202  is dev score for C= 0.001  and percent= 0.5\n",
      "0.251557632399  is dev score for C= 0.01  and percent= 0.5\n",
      "0.246884735202  is dev score for C= 0.1  and percent= 0.5\n",
      "0.244548286604  is dev score for C= 10.0  and percent= 0.5\n",
      "0.236760124611  is dev score for C= 1000.0  and percent= 0.5\n",
      "0.246884735202  is dev score for C= 0.001  and percent= 0.75\n",
      "0.252336448598  is dev score for C= 0.01  and percent= 0.75\n",
      "0.25  is dev score for C= 0.1  and percent= 0.75\n",
      "0.246884735202  is dev score for C= 10.0  and percent= 0.75\n",
      "0.222741433022  is dev score for C= 1000.0  and percent= 0.75\n",
      "0.247663551402  is dev score for C= 0.001  and percent= 1\n",
      "0.252336448598  is dev score for C= 0.01  and percent= 1\n",
      "0.249221183801  is dev score for C= 0.1  and percent= 1\n",
      "0.244548286604  is dev score for C= 10.0  and percent= 1\n",
      "0.228971962617  is dev score for C= 1000.0  and percent= 1\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "for percent in [0.5,0.75,1]:\n",
    "    vectorizer = CountVectorizer(ngram_range=(1, 1),max_features=math.ceil(percent*12196))\n",
    "    X=vectorizer.fit_transform(corpus)\n",
    "    feature_list=vectorizer.get_feature_names()\n",
    "    vectorizer_2=CountVectorizer(vocabulary = feature_list)\n",
    "    X2=vectorizer_2.fit_transform(dev_corpus)\n",
    "    for i in [1e-3,1e-2,1e-1,1e1,1e3]:\n",
    "        logreg = linear_model.LogisticRegression(C=i)\n",
    "        model = logreg.fit(X,ratings)\n",
    "        predicted=logreg.predict(X2)\n",
    "        score=accuracy_score(dev_ratings,predicted)\n",
    "        print(score, \" is dev score for C=\",i, \" and percent=\",percent)          \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6098  is feature list length\n",
      "0.246884735202  is dev score for C= 0.001  and percent= 0.5\n",
      "0.251557632399  is dev score for C= 0.01  and percent= 0.5\n",
      "0.246884735202  is dev score for C= 0.1  and percent= 0.5\n",
      "9147  is feature list length\n",
      "0.246884735202  is dev score for C= 0.001  and percent= 0.75\n",
      "0.252336448598  is dev score for C= 0.01  and percent= 0.75\n",
      "0.25  is dev score for C= 0.1  and percent= 0.75\n",
      "9757  is feature list length\n",
      "0.247663551402  is dev score for C= 0.001  and percent= 0.8\n",
      "0.252336448598  is dev score for C= 0.01  and percent= 0.8\n",
      "0.248442367601  is dev score for C= 0.1  and percent= 0.8\n",
      "10977  is feature list length\n",
      "0.247663551402  is dev score for C= 0.001  and percent= 0.9\n",
      "0.252336448598  is dev score for C= 0.01  and percent= 0.9\n",
      "0.248442367601  is dev score for C= 0.1  and percent= 0.9\n",
      "12196  is feature list length\n",
      "0.247663551402  is dev score for C= 0.001  and percent= 1\n",
      "0.252336448598  is dev score for C= 0.01  and percent= 1\n",
      "0.249221183801  is dev score for C= 0.1  and percent= 1\n"
     ]
    }
   ],
   "source": [
    "for percent in [0.5,0.75,0.8,0.9,1]:\n",
    "    vectorizer = CountVectorizer(ngram_range=(1, 1),max_features=math.ceil(percent*12196))\n",
    "    X=vectorizer.fit_transform(corpus)\n",
    "    feature_list=vectorizer.get_feature_names()\n",
    "    print(len(feature_list), \" is feature list length\")\n",
    "    vectorizer_2=CountVectorizer(vocabulary = feature_list)\n",
    "    X2=vectorizer_2.fit_transform(dev_corpus)\n",
    "    for i in [1e-3,1e-2,1e-1]:\n",
    "        logreg = linear_model.LogisticRegression(C=i)\n",
    "        model = logreg.fit(X,ratings)\n",
    "        predicted=logreg.predict(X2)\n",
    "        score=accuracy_score(dev_ratings,predicted)\n",
    "        print(score, \" is dev score for C=\",i, \" and percent=\",percent)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184932  is feature list length\n",
      "0.246105919003  is dev score for C= 0.001  and percent= 0.5\n",
      "0.257009345794  is dev score for C= 0.01  and percent= 0.5\n",
      "0.242990654206  is dev score for C= 0.1  and percent= 0.5\n",
      "277398  is feature list length\n",
      "0.246105919003  is dev score for C= 0.001  and percent= 0.75\n",
      "0.259345794393  is dev score for C= 0.01  and percent= 0.75\n",
      "0.242990654206  is dev score for C= 0.1  and percent= 0.75\n",
      "295891  is feature list length\n",
      "0.246105919003  is dev score for C= 0.001  and percent= 0.8\n",
      "0.260124610592  is dev score for C= 0.01  and percent= 0.8\n",
      "0.243769470405  is dev score for C= 0.1  and percent= 0.8\n",
      "332877  is feature list length\n",
      "0.246884735202  is dev score for C= 0.001  and percent= 0.9\n",
      "0.259345794393  is dev score for C= 0.01  and percent= 0.9\n",
      "0.244548286604  is dev score for C= 0.1  and percent= 0.9\n",
      "369863  is feature list length\n",
      "0.246884735202  is dev score for C= 0.001  and percent= 1\n",
      "0.258566978193  is dev score for C= 0.01  and percent= 1\n",
      "0.244548286604  is dev score for C= 0.1  and percent= 1\n"
     ]
    }
   ],
   "source": [
    "for percent in [0.5,0.75,0.8,0.9,1]:\n",
    "    vectorizer = CountVectorizer(ngram_range=(1, 4),max_features=math.ceil(percent*369863))\n",
    "    X=vectorizer.fit_transform(corpus)\n",
    "    feature_list=vectorizer.get_feature_names()\n",
    "    print(len(feature_list), \" is feature list length\")\n",
    "    vectorizer_2=CountVectorizer(vocabulary = feature_list)\n",
    "    X2=vectorizer_2.fit_transform(dev_corpus)\n",
    "    for i in [1e-3,1e-2,1e-1]:\n",
    "        logreg = linear_model.LogisticRegression(C=i)\n",
    "        model = logreg.fit(X,ratings)\n",
    "        predicted=logreg.predict(X2)\n",
    "        score=accuracy_score(dev_ratings,predicted)\n",
    "        print(score, \" is dev score for C=\",i, \" and percent=\",percent)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  is the ngram val\n",
      "0.193146417445  is tfidf dev score for C= 0.001\n",
      "0.195482866044  is tfidf dev score for C= 0.01\n",
      "0.240654205607  is tfidf dev score for C= 0.1\n",
      "0.242211838006  is tfidf dev score for C= 10.0\n",
      "0.235202492212  is tfidf dev score for C= 1000.0\n",
      "0.232866043614  is tfidf dev score for C= 100000.0\n",
      "0.231308411215  is tfidf dev score for C= 10000000.0\n",
      "2  is the ngram val\n",
      "0.193146417445  is tfidf dev score for C= 0.001\n",
      "0.193146417445  is tfidf dev score for C= 0.01\n",
      "0.232866043614  is tfidf dev score for C= 0.1\n",
      "0.245327102804  is tfidf dev score for C= 10.0\n",
      "0.239096573209  is tfidf dev score for C= 1000.0\n",
      "0.238317757009  is tfidf dev score for C= 100000.0\n",
      "0.23753894081  is tfidf dev score for C= 10000000.0\n",
      "3  is the ngram val\n",
      "0.193146417445  is tfidf dev score for C= 0.001\n",
      "0.193146417445  is tfidf dev score for C= 0.01\n",
      "0.22507788162  is tfidf dev score for C= 0.1\n",
      "0.246105919003  is tfidf dev score for C= 10.0\n",
      "0.239096573209  is tfidf dev score for C= 1000.0\n",
      "0.240654205607  is tfidf dev score for C= 100000.0\n",
      "0.246105919003  is tfidf dev score for C= 10000000.0\n",
      "4  is the ngram val\n",
      "0.193146417445  is tfidf dev score for C= 0.001\n",
      "0.193146417445  is tfidf dev score for C= 0.01\n",
      "0.221183800623  is tfidf dev score for C= 0.1\n",
      "0.251557632399  is tfidf dev score for C= 10.0\n",
      "0.242211838006  is tfidf dev score for C= 1000.0\n",
      "0.242211838006  is tfidf dev score for C= 100000.0\n",
      "0.239875389408  is tfidf dev score for C= 10000000.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "for ngram in range(1,5):\n",
    "    vectorizer = TfidfVectorizer(ngram_range=(1, ngram))\n",
    "    X=vectorizer.fit_transform(corpus)\n",
    "    feature_list=vectorizer.get_feature_names()\n",
    "    dev_corpus, dev_ratings=get_corpus_ratings(\"liar_dataset/valid.tsv\")\n",
    "    vectorizer_2=TfidfVectorizer(vocabulary = feature_list)\n",
    "    X2=vectorizer_2.fit_transform(dev_corpus)\n",
    "    print(ngram, \" is the ngram val\")\n",
    "    for i in [1e-3,1e-2,1e-1,1e1,1e3,1e5,1e7]:\n",
    "        logreg = linear_model.LogisticRegression(C=i)\n",
    "        model = logreg.fit(X,ratings)\n",
    "        predicted=logreg.predict(X2)\n",
    "        score=accuracy_score(dev_ratings,predicted)\n",
    "        print(score, \" is tfidf dev score for C=\",i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.231254932912  is test score for C= 0.01\n"
     ]
    }
   ],
   "source": [
    "#4-grams and 5-grams have same results\n",
    "#best is 4-gram C=0.01 @ .258\n",
    "\n",
    "#run on test dataset\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 4))\n",
    "X=vectorizer.fit_transform(corpus)\n",
    "feature_list=vectorizer.get_feature_names()\n",
    "dev_corpus, dev_ratings=get_corpus_ratings(\"liar_dataset/test.tsv\")\n",
    "vectorizer_2=CountVectorizer(vocabulary = feature_list)\n",
    "X2=vectorizer_2.fit_transform(dev_corpus)\n",
    "logreg = linear_model.LogisticRegression(C=1e-2)\n",
    "model = logreg.fit(X,ratings)\n",
    "predicted=logreg.predict(X2)\n",
    "score=accuracy_score(dev_ratings,predicted)\n",
    "print(score, \" is test score for C=\",1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "def getIndicesVector(text_arr, word_to_indx, max_length=50):\n",
    "    nil_indx = 0\n",
    "    text_indx = [ word_to_indx[x.lower().encode('utf8')] if x.lower().encode('utf8') in word_to_indx else nil_indx for x in text_arr][:max_length]\n",
    "    if len(text_indx) < max_length:\n",
    "        text_indx.extend( [nil_indx for _ in range(max_length - len(text_indx))])\n",
    "    text_indx=np.array(text_indx)\n",
    "    return text_indx\n",
    "\n",
    "def getEmbeddingVector(filename):\n",
    "    lines = []\n",
    "    with gzip.open(filename) as file:\n",
    "        lines = file.readlines()\n",
    "        file.close()\n",
    "    embedding_vector = []\n",
    "    word_to_indx = {}\n",
    "    for indx, l in enumerate(lines):\n",
    "        word, emb = l.split()[0], l.split()[1:]\n",
    "        vector = [float(x) for x in emb ]\n",
    "        if indx == 0:\n",
    "            embedding_vector.append( np.zeros( len(vector) ) )\n",
    "        embedding_vector.append(vector)\n",
    "        word_to_indx[word] = indx+1\n",
    "    embedding_vector = np.array(embedding_vector)\n",
    "    return embedding_vector, word_to_indx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10240  is len corpus\n"
     ]
    }
   ],
   "source": [
    "embeddings, word_to_indx = getEmbeddingVector('word_vectors.txt.gz')\n",
    "print(len(corpus), \" is len corpus\")\n",
    "def corpus_to_embed(corpus):\n",
    "    embeddings_corpus=[]\n",
    "    for text in corpus:\n",
    "        x=getIndicesVector(text.split(),word_to_indx)\n",
    "        embeddings_corpus.append(x)\n",
    "    embeddings_corpus=np.matrix(embeddings_corpus)\n",
    "    return embeddings_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print('pony' in word_to_indx)\n",
    "print('pony'.encode('utf-8') in word_to_indx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.195737963694  is embed logreg dev score for C= 0.001\n",
      "0.197316495659  is embed logreg dev score for C= 0.01\n",
      "0.191791633781  is embed logreg dev score for C= 0.1\n",
      "0.18863456985  is embed logreg dev score for C= 10.0\n",
      "0.18863456985  is embed logreg dev score for C= 1000.0\n"
     ]
    }
   ],
   "source": [
    "#utf8_corpus=[x.encode('utf8') for x in corpus]\n",
    "X=corpus_to_embed(corpus)\n",
    "#utf8_dev_corpus=[x.encode('utf8') for x in dev_corpus]\n",
    "X2=corpus_to_embed(dev_corpus)\n",
    "for i in [1e-3,1e-2,1e-1,1e1,1e3]:\n",
    "    logreg = linear_model.LogisticRegression(C=i)\n",
    "    model = logreg.fit(X,ratings)\n",
    "    predicted=logreg.predict(X2)\n",
    "    score=accuracy_score(dev_ratings,predicted)\n",
    "    print(score, \" is embed logreg dev score for C=\",i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting with the  1 -gram\n",
      "0.193146417445  is dev score for C= 0.001\n",
      "0.252336448598  is dev score for C= 0.01\n",
      "0.239096573209  is dev score for C= 0.1\n",
      "0.250778816199  is dev score for C= 10.0\n",
      "0.250778816199  is dev score for C= 1000.0\n",
      "0.250778816199  is dev score for C= 100000.0\n",
      "0.250778816199  is dev score for C= 10000000.0\n",
      "starting with the  2 -gram\n",
      "0.193146417445  is dev score for C= 0.001\n",
      "0.247663551402  is dev score for C= 0.01\n",
      "0.242211838006  is dev score for C= 0.1\n",
      "0.243769470405  is dev score for C= 10.0\n",
      "0.243769470405  is dev score for C= 1000.0\n",
      "0.243769470405  is dev score for C= 100000.0\n",
      "0.243769470405  is dev score for C= 10000000.0\n",
      "starting with the  3 -gram\n",
      "0.193146417445  is dev score for C= 0.001\n",
      "0.242990654206  is dev score for C= 0.01\n",
      "0.23753894081  is dev score for C= 0.1\n",
      "0.245327102804  is dev score for C= 10.0\n",
      "0.245327102804  is dev score for C= 1000.0\n",
      "0.245327102804  is dev score for C= 100000.0\n",
      "0.245327102804  is dev score for C= 10000000.0\n",
      "starting with the  4 -gram\n",
      "0.193146417445  is dev score for C= 0.001\n",
      "0.239096573209  is dev score for C= 0.01\n",
      "0.235981308411  is dev score for C= 0.1\n",
      "0.238317757009  is dev score for C= 10.0\n",
      "0.238317757009  is dev score for C= 1000.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-106-2947a59ec8db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1e-2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1e-1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1e1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1e3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1e5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1e7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0msvc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mratings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mpredicted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msvc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mscore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_ratings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nicoleobrien/anaconda/lib/python3.6/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nicoleobrien/anaconda/lib/python3.6/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_sparse_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    276\u001b[0m                 \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m                 \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshrinking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobability\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m                 random_seed)\n\u001b[0m\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32msklearn/svm/libsvm_sparse.pyx\u001b[0m in \u001b[0;36msklearn.svm.libsvm_sparse.libsvm_sparse_train (sklearn/svm/libsvm_sparse.c:2793)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/Users/nicoleobrien/anaconda/lib/python3.6/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;34m\"\"\"base matrix class for compressed row and column oriented matrices\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0m_data_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#moving on to SVM\n",
    "#start with linear, also try rbf\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "for n in range(1,5):\n",
    "    vectorizer = CountVectorizer(ngram_range=(1, n))\n",
    "    X=vectorizer.fit_transform(corpus)\n",
    "    feature_list=vectorizer.get_feature_names()\n",
    "    dev_corpus, dev_ratings=get_corpus_ratings(\"liar_dataset/valid.tsv\")\n",
    "    vectorizer_2=CountVectorizer(vocabulary = feature_list)\n",
    "    X2=vectorizer_2.fit_transform(dev_corpus)\n",
    "    print(\"starting with the \",n,\"-gram\")\n",
    "    for i in [1e-3,1e-2,1e-1,1e1,1e3,1e5,1e7]:\n",
    "        svc = SVC(C=i,kernel='linear')\n",
    "        model = svc.fit(X,ratings)\n",
    "        predicted=svc.predict(X2)\n",
    "        score=accuracy_score(dev_ratings,predicted)\n",
    "        print(score, \" is dev score for C=\",i)\n",
    "    \n",
    "#best is C=0.01, 1-gram, bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting with the  1 -gram\n",
      "0.193146417445  is dev score for C= 0.001\n",
      "0.193146417445  is dev score for C= 0.1\n",
      "0.193146417445  is dev score for C= 10.0\n",
      "0.249221183801  is dev score for C= 1000.0\n",
      "0.240654205607  is dev score for C= 100000.0\n",
      "starting with the  2 -gram\n",
      "0.193146417445  is dev score for C= 0.001\n",
      "0.193146417445  is dev score for C= 0.1\n",
      "0.193146417445  is dev score for C= 10.0\n",
      "0.248442367601  is dev score for C= 1000.0\n",
      "0.242211838006  is dev score for C= 100000.0\n",
      "starting with the  3 -gram\n",
      "0.193146417445  is dev score for C= 0.001\n",
      "0.193146417445  is dev score for C= 0.1\n",
      "0.193146417445  is dev score for C= 10.0\n",
      "0.243769470405  is dev score for C= 1000.0\n",
      "0.242211838006  is dev score for C= 100000.0\n",
      "starting with the  4 -gram\n",
      "0.193146417445  is dev score for C= 0.001\n",
      "0.193146417445  is dev score for C= 0.1\n",
      "0.193146417445  is dev score for C= 10.0\n",
      "0.248442367601  is dev score for C= 1000.0\n",
      "0.236760124611  is dev score for C= 100000.0\n"
     ]
    }
   ],
   "source": [
    "#rbf kernel\n",
    "for n in range(1,5):\n",
    "    vectorizer = CountVectorizer(ngram_range=(1, n))\n",
    "    X=vectorizer.fit_transform(corpus)\n",
    "    feature_list=vectorizer.get_feature_names()\n",
    "    dev_corpus, dev_ratings=get_corpus_ratings(\"liar_dataset/valid.tsv\")\n",
    "    vectorizer_2=CountVectorizer(vocabulary = feature_list)\n",
    "    X2=vectorizer_2.fit_transform(dev_corpus)\n",
    "    print(\"starting with the \",n,\"-gram\")\n",
    "    for i in [1e-3,1e-1,1e1,1e3,1e5]:\n",
    "        svc = SVC(C=i,kernel='rbf')\n",
    "        model = svc.fit(X,ratings)\n",
    "        predicted=svc.predict(X2)\n",
    "        score=accuracy_score(dev_ratings,predicted)\n",
    "        print(score, \" is dev score for C=\",i)\n",
    "    \n",
    "#best is C=0.01, 1-gram, bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
